{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 22:59:54.584976: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-07 22:59:54.611020: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-07 22:59:55.089692: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n",
      "[WARNING] From /home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term [deprecation.py _log_deprecation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/hl-turing/VSCodeProjects/Flavio/CARLA/wandb.py\", line 1, in <module>\n",
      "    import wandb\n",
      "  File \"/home/hl-turing/VSCodeProjects/Flavio/CARLA/wandb.py\", line 38, in <module>\n",
      "    wandb.login()\n",
      "    ^^^^^^^^^^^\n",
      "AttributeError: partially initialized module 'wandb' has no attribute 'login' (most likely due to a circular import)\n"
     ]
    },
    {
     "ename": "ServiceStartProcessError",
     "evalue": "The wandb service process exited with 1. Ensure that `sys.executable` is a valid python interpreter. You can override it with the `_executable` setting or with the `WANDB__EXECUTABLE` environment variable.\n{'command': ['/home/hl-turing/anaconda3/envs/cfgnn/bin/python', '-m', 'wandb', 'service', '--debug', '--port-filename', '/tmp/tmp03sz3k_8/port-250384.txt', '--pid', '250384', '--serve-sock'], 'sys_executable': '/home/hl-turing/anaconda3/envs/cfgnn/bin/python', 'which_python': '/home/hl-turing/anaconda3/envs/cfgnn/bin/python3', 'proc_out': '', 'proc_err': ''}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServiceStartProcessError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwandb\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m wandb\u001b[39m.\u001b[39;49mlogin(key\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m61aac9b0b0cd9f6b611dda5a9137dd62870e5cdf\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_login.py:81\u001b[0m, in \u001b[0;36mlogin\u001b[0;34m(anonymous, key, relogin, host, force, timeout, verify)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Set up W&B login credentials.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \n\u001b[1;32m     57\u001b[0m \u001b[39mBy default, this will only store the credentials locally without\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39m    UsageError - if api_key cannot be configured and no tty\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m _handle_host_wandb_setting(host)\n\u001b[0;32m---> 81\u001b[0m \u001b[39mif\u001b[39;00m wandb\u001b[39m.\u001b[39;49msetup()\u001b[39m.\u001b[39m_settings\u001b[39m.\u001b[39m_noop:\n\u001b[1;32m     82\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     84\u001b[0m configured \u001b[39m=\u001b[39m _login(\n\u001b[1;32m     85\u001b[0m     anonymous\u001b[39m=\u001b[39manonymous,\n\u001b[1;32m     86\u001b[0m     key\u001b[39m=\u001b[39mkey,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[1;32m     91\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:325\u001b[0m, in \u001b[0;36msetup\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup\u001b[39m(\n\u001b[1;32m    323\u001b[0m     settings: Optional[Settings] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    324\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[\u001b[39m\"\u001b[39m\u001b[39m_WandbSetup\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 325\u001b[0m     ret \u001b[39m=\u001b[39m _setup(settings\u001b[39m=\u001b[39;49msettings)\n\u001b[1;32m    326\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:318\u001b[0m, in \u001b[0;36m_setup\u001b[0;34m(settings, _reset)\u001b[0m\n\u001b[1;32m    315\u001b[0m     teardown()\n\u001b[1;32m    316\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m wl \u001b[39m=\u001b[39m _WandbSetup(settings\u001b[39m=\u001b[39;49msettings)\n\u001b[1;32m    319\u001b[0m \u001b[39mreturn\u001b[39;00m wl\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:303\u001b[0m, in \u001b[0;36m_WandbSetup.__init__\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m    301\u001b[0m     _WandbSetup\u001b[39m.\u001b[39m_instance\u001b[39m.\u001b[39m_update(settings\u001b[39m=\u001b[39msettings)\n\u001b[1;32m    302\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m _WandbSetup\u001b[39m.\u001b[39m_instance \u001b[39m=\u001b[39m _WandbSetup__WandbSetup(settings\u001b[39m=\u001b[39;49msettings, pid\u001b[39m=\u001b[39;49mpid)\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:114\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup.__init__\u001b[0;34m(self, pid, settings, environ)\u001b[0m\n\u001b[1;32m    111\u001b[0m wandb\u001b[39m.\u001b[39mtermsetup(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_settings, logger)\n\u001b[1;32m    113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check()\n\u001b[0;32m--> 114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup()\n\u001b[1;32m    116\u001b[0m tracelog_mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_settings\u001b[39m.\u001b[39m_tracelog\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m tracelog_mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:250\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup._setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_setup\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_manager()\n\u001b[1;32m    252\u001b[0m     sweep_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_settings\u001b[39m.\u001b[39msweep_param_path\n\u001b[1;32m    253\u001b[0m     \u001b[39mif\u001b[39;00m sweep_path:\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:283\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup._setup_manager\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_settings\u001b[39m.\u001b[39m_disable_service:\n\u001b[1;32m    282\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_manager \u001b[39m=\u001b[39m wandb_manager\u001b[39m.\u001b[39;49m_Manager(settings\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_settings)\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_manager.py:145\u001b[0m, in \u001b[0;36m_Manager.__init__\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m    143\u001b[0m token \u001b[39m=\u001b[39m _ManagerToken\u001b[39m.\u001b[39mfrom_environment()\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m token:\n\u001b[0;32m--> 145\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_service\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m    146\u001b[0m     host \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlocalhost\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m     transport \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtcp\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/service/service.py:253\u001b[0m, in \u001b[0;36m_Service.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstart\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch_server()\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/service/service.py:247\u001b[0m, in \u001b[0;36m_Service._launch_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_ports(fname, proc\u001b[39m=\u001b[39minternal_proc)\n\u001b[1;32m    246\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 247\u001b[0m     _sentry\u001b[39m.\u001b[39;49mreraise(e)\n\u001b[1;32m    248\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_startup_debug_print(\u001b[39m\"\u001b[39m\u001b[39mwait_ports_done\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_proc \u001b[39m=\u001b[39m internal_proc\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/analytics/sentry.py:155\u001b[0m, in \u001b[0;36mSentry.reraise\u001b[0;34m(self, exc)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexception(exc)\n\u001b[1;32m    153\u001b[0m \u001b[39m# this will messily add this \"reraise\" function to the stack trace,\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39m# but hopefully it's not too bad\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mwith_traceback(sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/service/service.py:245\u001b[0m, in \u001b[0;36m_Service._launch_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_startup_debug_print(\u001b[39m\"\u001b[39m\u001b[39mwait_ports\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    244\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_ports(fname, proc\u001b[39m=\u001b[39;49minternal_proc)\n\u001b[1;32m    246\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    247\u001b[0m     _sentry\u001b[39m.\u001b[39mreraise(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/service/service.py:109\u001b[0m, in \u001b[0;36m_Service._wait_for_ports\u001b[0;34m(self, fname, proc)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m proc \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mpoll():\n\u001b[1;32m     95\u001b[0m     \u001b[39m# process finished\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[39m# define these variables for sentry context grab:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39m# proc_out = proc.stdout.read()\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39m# proc_err = proc.stderr.read()\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     context \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    103\u001b[0m         command\u001b[39m=\u001b[39mproc\u001b[39m.\u001b[39margs,\n\u001b[1;32m    104\u001b[0m         sys_executable\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mexecutable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m         proc_err\u001b[39m=\u001b[39mproc\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mread() \u001b[39mif\u001b[39;00m proc\u001b[39m.\u001b[39mstderr \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    108\u001b[0m     )\n\u001b[0;32m--> 109\u001b[0m     \u001b[39mraise\u001b[39;00m ServiceStartProcessError(\n\u001b[1;32m    110\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe wandb service process exited with \u001b[39m\u001b[39m{\u001b[39;00mproc\u001b[39m.\u001b[39mreturncode\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEnsure that `sys.executable` is a valid python interpreter. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can override it with the `_executable` setting \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor with the `WANDB__EXECUTABLE` environment variable.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mcontext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    115\u001b[0m         context\u001b[39m=\u001b[39mcontext,\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(fname):\n\u001b[1;32m    118\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.2\u001b[39m)\n",
      "\u001b[0;31mServiceStartProcessError\u001b[0m: The wandb service process exited with 1. Ensure that `sys.executable` is a valid python interpreter. You can override it with the `_executable` setting or with the `WANDB__EXECUTABLE` environment variable.\n{'command': ['/home/hl-turing/anaconda3/envs/cfgnn/bin/python', '-m', 'wandb', 'service', '--debug', '--port-filename', '/tmp/tmp03sz3k_8/port-250384.txt', '--pid', '250384', '--serve-sock'], 'sys_executable': '/home/hl-turing/anaconda3/envs/cfgnn/bin/python', 'which_python': '/home/hl-turing/anaconda3/envs/cfgnn/bin/python3', 'proc_out': '', 'proc_err': ''}"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key='61aac9b0b0cd9f6b611dda5a9137dd62870e5cdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 23:00:07.120650: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-07 23:00:07.146320: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-07 23:00:07.619535: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n",
      "[WARNING] From /home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term [deprecation.py _log_deprecation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/hl-turing/VSCodeProjects/Flavio/CARLA/wandb.py\", line 1, in <module>\n",
      "    import wandb\n",
      "  File \"/home/hl-turing/VSCodeProjects/Flavio/CARLA/wandb.py\", line 38, in <module>\n",
      "    wandb.login()\n",
      "    ^^^^^^^^^^^\n",
      "AttributeError: partially initialized module 'wandb' has no attribute 'login' (most likely due to a circular import)\n"
     ]
    },
    {
     "ename": "ServiceStartProcessError",
     "evalue": "The wandb service process exited with 1. Ensure that `sys.executable` is a valid python interpreter. You can override it with the `_executable` setting or with the `WANDB__EXECUTABLE` environment variable.\n{'command': ['/home/hl-turing/anaconda3/envs/cfgnn/bin/python', '-m', 'wandb', 'service', '--debug', '--port-filename', '/tmp/tmpdw1tkrsa/port-250384.txt', '--pid', '250384', '--serve-sock'], 'sys_executable': '/home/hl-turing/anaconda3/envs/cfgnn/bin/python', 'which_python': '/home/hl-turing/anaconda3/envs/cfgnn/bin/python3', 'proc_out': '', 'proc_err': ''}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServiceStartProcessError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwandb\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m wandb\u001b[39m.\u001b[39;49mlogin()\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_login.py:81\u001b[0m, in \u001b[0;36mlogin\u001b[0;34m(anonymous, key, relogin, host, force, timeout, verify)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Set up W&B login credentials.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \n\u001b[1;32m     57\u001b[0m \u001b[39mBy default, this will only store the credentials locally without\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39m    UsageError - if api_key cannot be configured and no tty\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m _handle_host_wandb_setting(host)\n\u001b[0;32m---> 81\u001b[0m \u001b[39mif\u001b[39;00m wandb\u001b[39m.\u001b[39;49msetup()\u001b[39m.\u001b[39m_settings\u001b[39m.\u001b[39m_noop:\n\u001b[1;32m     82\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     84\u001b[0m configured \u001b[39m=\u001b[39m _login(\n\u001b[1;32m     85\u001b[0m     anonymous\u001b[39m=\u001b[39manonymous,\n\u001b[1;32m     86\u001b[0m     key\u001b[39m=\u001b[39mkey,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[1;32m     91\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:325\u001b[0m, in \u001b[0;36msetup\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup\u001b[39m(\n\u001b[1;32m    323\u001b[0m     settings: Optional[Settings] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    324\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[\u001b[39m\"\u001b[39m\u001b[39m_WandbSetup\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 325\u001b[0m     ret \u001b[39m=\u001b[39m _setup(settings\u001b[39m=\u001b[39;49msettings)\n\u001b[1;32m    326\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:318\u001b[0m, in \u001b[0;36m_setup\u001b[0;34m(settings, _reset)\u001b[0m\n\u001b[1;32m    315\u001b[0m     teardown()\n\u001b[1;32m    316\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m wl \u001b[39m=\u001b[39m _WandbSetup(settings\u001b[39m=\u001b[39;49msettings)\n\u001b[1;32m    319\u001b[0m \u001b[39mreturn\u001b[39;00m wl\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:303\u001b[0m, in \u001b[0;36m_WandbSetup.__init__\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m    301\u001b[0m     _WandbSetup\u001b[39m.\u001b[39m_instance\u001b[39m.\u001b[39m_update(settings\u001b[39m=\u001b[39msettings)\n\u001b[1;32m    302\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m _WandbSetup\u001b[39m.\u001b[39m_instance \u001b[39m=\u001b[39m _WandbSetup__WandbSetup(settings\u001b[39m=\u001b[39;49msettings, pid\u001b[39m=\u001b[39;49mpid)\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:114\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup.__init__\u001b[0;34m(self, pid, settings, environ)\u001b[0m\n\u001b[1;32m    111\u001b[0m wandb\u001b[39m.\u001b[39mtermsetup(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_settings, logger)\n\u001b[1;32m    113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check()\n\u001b[0;32m--> 114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup()\n\u001b[1;32m    116\u001b[0m tracelog_mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_settings\u001b[39m.\u001b[39m_tracelog\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m tracelog_mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:250\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup._setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_setup\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_manager()\n\u001b[1;32m    252\u001b[0m     sweep_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_settings\u001b[39m.\u001b[39msweep_param_path\n\u001b[1;32m    253\u001b[0m     \u001b[39mif\u001b[39;00m sweep_path:\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:283\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup._setup_manager\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_settings\u001b[39m.\u001b[39m_disable_service:\n\u001b[1;32m    282\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_manager \u001b[39m=\u001b[39m wandb_manager\u001b[39m.\u001b[39;49m_Manager(settings\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_settings)\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_manager.py:145\u001b[0m, in \u001b[0;36m_Manager.__init__\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m    143\u001b[0m token \u001b[39m=\u001b[39m _ManagerToken\u001b[39m.\u001b[39mfrom_environment()\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m token:\n\u001b[0;32m--> 145\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_service\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m    146\u001b[0m     host \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlocalhost\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m     transport \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtcp\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/service/service.py:253\u001b[0m, in \u001b[0;36m_Service.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstart\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch_server()\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/service/service.py:247\u001b[0m, in \u001b[0;36m_Service._launch_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_ports(fname, proc\u001b[39m=\u001b[39minternal_proc)\n\u001b[1;32m    246\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 247\u001b[0m     _sentry\u001b[39m.\u001b[39;49mreraise(e)\n\u001b[1;32m    248\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_startup_debug_print(\u001b[39m\"\u001b[39m\u001b[39mwait_ports_done\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_proc \u001b[39m=\u001b[39m internal_proc\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/analytics/sentry.py:155\u001b[0m, in \u001b[0;36mSentry.reraise\u001b[0;34m(self, exc)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexception(exc)\n\u001b[1;32m    153\u001b[0m \u001b[39m# this will messily add this \"reraise\" function to the stack trace,\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39m# but hopefully it's not too bad\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mwith_traceback(sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/service/service.py:245\u001b[0m, in \u001b[0;36m_Service._launch_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_startup_debug_print(\u001b[39m\"\u001b[39m\u001b[39mwait_ports\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    244\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_ports(fname, proc\u001b[39m=\u001b[39;49minternal_proc)\n\u001b[1;32m    246\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    247\u001b[0m     _sentry\u001b[39m.\u001b[39mreraise(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/service/service.py:109\u001b[0m, in \u001b[0;36m_Service._wait_for_ports\u001b[0;34m(self, fname, proc)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m proc \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mpoll():\n\u001b[1;32m     95\u001b[0m     \u001b[39m# process finished\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[39m# define these variables for sentry context grab:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39m# proc_out = proc.stdout.read()\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39m# proc_err = proc.stderr.read()\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     context \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    103\u001b[0m         command\u001b[39m=\u001b[39mproc\u001b[39m.\u001b[39margs,\n\u001b[1;32m    104\u001b[0m         sys_executable\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mexecutable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m         proc_err\u001b[39m=\u001b[39mproc\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mread() \u001b[39mif\u001b[39;00m proc\u001b[39m.\u001b[39mstderr \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    108\u001b[0m     )\n\u001b[0;32m--> 109\u001b[0m     \u001b[39mraise\u001b[39;00m ServiceStartProcessError(\n\u001b[1;32m    110\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe wandb service process exited with \u001b[39m\u001b[39m{\u001b[39;00mproc\u001b[39m.\u001b[39mreturncode\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEnsure that `sys.executable` is a valid python interpreter. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can override it with the `_executable` setting \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor with the `WANDB__EXECUTABLE` environment variable.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mcontext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    115\u001b[0m         context\u001b[39m=\u001b[39mcontext,\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(fname):\n\u001b[1;32m    118\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.2\u001b[39m)\n",
      "\u001b[0;31mServiceStartProcessError\u001b[0m: The wandb service process exited with 1. Ensure that `sys.executable` is a valid python interpreter. You can override it with the `_executable` setting or with the `WANDB__EXECUTABLE` environment variable.\n{'command': ['/home/hl-turing/anaconda3/envs/cfgnn/bin/python', '-m', 'wandb', 'service', '--debug', '--port-filename', '/tmp/tmpdw1tkrsa/port-250384.txt', '--pid', '250384', '--serve-sock'], 'sys_executable': '/home/hl-turing/anaconda3/envs/cfgnn/bin/python', 'which_python': '/home/hl-turing/anaconda3/envs/cfgnn/bin/python3', 'proc_out': '', 'proc_err': ''}"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
    "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track MetaData and HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    hidden_list_conv = [31,31,31],\n",
    "    hidden_list_att = [50 for _ in range(7)], # for GIN and GAT\n",
    "    alpha=0.2, # for GAT\n",
    "    nheads=8, # for GAT\n",
    "    dropout = 0.0,\n",
    "    epochs=1000,\n",
    "    classes=2,\n",
    "    batch_size=1024,\n",
    "    num_neig = [30]*3,\n",
    "    learning_rate=0.002,\n",
    "    clip = 2.0,\n",
    "    dataset=\"AML\",\n",
    "    architecture=\"gin\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define the overall pipeline,\n",
    "which is pretty typical for model-training:\n",
    "\n",
    "1. we first `make` a model, plus associated data and optimizer, then\n",
    "2. we `train` the model accordingly and finally\n",
    "3. `test` it to see how training went."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "from carla.data.catalog import AMLtoGraph\n",
    "\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch_geometric.nn.dense import DenseGCNConv\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torcheval.metrics import MulticlassAccuracy, MulticlassF1Score, BinaryF1Score, BinaryAccuracy\n",
    "from carla.models.catalog.parse_gnn import normalize_adj"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Model\n",
    "from carla.models.catalog.GAT_TORCH import GAT as gat_torch\n",
    "from carla.models.catalog.GAT_COO_TORCH import GAT_COO as gat_coo_torch\n",
    "\n",
    "from carla.models.catalog.GNN_TORCH import GCNSynthetic as gnn_torch\n",
    "from carla.models.catalog.GNN_COO_TORCH import GNN_COO as gnn_coo_torch\n",
    "\n",
    "from carla.models.catalog.GIN_TORCH import GIN as gin_torch\n",
    "from carla.models.catalog.GIN_COO_TORCH import GIN_COO as gin_coo_torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(config):\n",
    "    # Make the data\n",
    "    datagraph = get_data(path = \"/home/hl-turing/VSCodeProjects/Flavio/CARLA/data/AML_Laund_Clean.csv\")\n",
    "    train_loader = make_loader(datagraph, datagraph.train_mask, batch_size=config.batch_size, num_neig=config.num_neig)\n",
    "    test_loader = make_loader(datagraph, datagraph.test_mask, batch_size=config.batch_size, num_neig=config.num_neig)\n",
    "\n",
    "    # Make the model\n",
    "    if config.architecture == 'gnn':\n",
    "        model = gnn_torch(\n",
    "                nfeat=len(datagraph.x[0]),\n",
    "                hid_list_conv=config.hidden_list_conv,\n",
    "                nclass=config.classes,\n",
    "                dropout=config.dropout,\n",
    "        ).to(device)\n",
    "    elif config.architecture == \"gat\":\n",
    "        #hidden_list_att = [50 for _ in range(3)]\n",
    "        model = gat_torch(\n",
    "                nfeat=len(datagraph.x[0]),\n",
    "                hid_list_att=config.hidden_list_att,  # da parametrizzare\n",
    "                hid_list_conv=config.hidden_list_conv,\n",
    "                nclass=config.classes,\n",
    "                dropout=config.dropout,\n",
    "                alpha=config.alpha,\n",
    "                nheads=config.nheads,\n",
    "            ).to(device)\n",
    "    elif config.architecture == \"gin\":\n",
    "            # forse definire hidden_list_att DA PARAMETRIZZARE\n",
    "        #hidden_list_att = [50 for _ in range(7)]\n",
    "        model = gin_torch(\n",
    "                nfeat=len(datagraph.x[0]),\n",
    "                hid_list_gin=config.hidden_list_att,  # da parametrizzare\n",
    "                hid_list_conv=config.hidden_list_conv,\n",
    "                nclass=config.classes,\n",
    "                dropout=config.dropout,\n",
    "                alpha=config.alpha,\n",
    "                nheads=config.nheads\n",
    "            ).to(device)\n",
    "    elif config.architecture == 'gnn_coo':\n",
    "        model = gnn_coo_torch(\n",
    "                nfeat=len(datagraph.x[0]),\n",
    "                hid_list_conv=config.hidden_list_conv,\n",
    "                nclass=config.classes,\n",
    "                dropout=config.dropout,\n",
    "        ).to(device)\n",
    "        \n",
    "    elif config.architecture == \"gat_coo\":\n",
    "            # forse definire hidden_list_att DA PARAMETRIZZARE\n",
    "        #hidden_list_att = [31 for _ in range(4)]\n",
    "        model = gat_coo_torch(\n",
    "                nfeat=len(datagraph.x[0]),\n",
    "                hid_list_att=config.hidden_list_att,  # da parametrizzare\n",
    "                hid_list_conv=config.hidden_list_conv,\n",
    "                nclass=config.classes,\n",
    "                dropout=config.dropout,\n",
    "                alpha=config.alpha,\n",
    "                nheads=len(config.hidden_list_att),\n",
    "            ).to(device)\n",
    "    elif config.architecture == \"gin_coo\":\n",
    "            # forse definire hidden_list_att DA PARAMETRIZZARE\n",
    "        #hidden_list_att = [31 for _ in range(4)]\n",
    "        model = gin_coo_torch(\n",
    "                nfeat=len(datagraph.x[0]),\n",
    "                hid_list_gin=config.hidden_list_att,  # da parametrizzare\n",
    "                hid_list_conv=config.hidden_list_conv,\n",
    "                edge_dim = datagraph.edge_attr.shape[1],\n",
    "                nclass=config.classes,\n",
    "                dropout=config.dropout\n",
    "            ).to(device)\n",
    "\n",
    "    # Make the loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=config.learning_rate)\n",
    "    \n",
    "    return model, train_loader, test_loader, criterion, optimizer\n",
    "\n",
    "def get_data(path):\n",
    "    data = AMLtoGraph(path)\n",
    "    datagraph = data.construct_GraphData()\n",
    "    return datagraph\n",
    "\n",
    "def make_loader(datagraph, mask, batch_size, num_neig):\n",
    "    loader = NeighborLoader(\n",
    "        datagraph,\n",
    "        num_neighbors=num_neig,\n",
    "        batch_size=batch_size,\n",
    "        input_nodes=mask\n",
    "    )\n",
    "    return loader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, config):\n",
    "    # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "    \n",
    "    metric = BinaryAccuracy()\n",
    "    # f1score = MulticlassF1Score(num_classes=2, average=\"macro\")\n",
    "    f1score = BinaryF1Score()\n",
    "    t_total = time.time()\n",
    "    # Run training and track with wandb\n",
    "\n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        t = time.time()\n",
    "        average_epoch_loss = 0.0\n",
    "        model.train()\n",
    "        for data in loader:\n",
    "            data.to(device)\n",
    "\n",
    "            adj = _create_adj_mat(data)\n",
    "            norm_adj = normalize_adj(adj).to(device)\n",
    "            features = torch.tensor(data.x).squeeze().to(device)\n",
    "            labels = torch.tensor(data.y).squeeze().long().to(device)\n",
    "\n",
    "            node_idx = [i for i in range(0, len(data.y))]\n",
    "            idx_train = torch.masked_select(torch.Tensor(node_idx, device=\"cpu\"), data.train_mask.cpu())\n",
    "            # idx_test = torch.masked_select(torch.Tensor(node_idx, device=\"cpu\"), data.test_mask.cpu())\n",
    "            idx_train = idx_train.type(torch.int64)\n",
    "            optimizer.zero_grad()\n",
    "            if config.architecture == \"gnn\" or config.architecture == \"gat\" or config.architecture == \"gin\":\n",
    "                features, norm_adj = features.to(device), norm_adj.to(device)\n",
    "                output = model(features, norm_adj).squeeze()\n",
    "            ## coo list \n",
    "            elif config.architecture == \"gnn_coo\" or config.architecture == \"gat_coo\" or config.architecture == \"gin_coo\":\n",
    "                features =  features.to(device)\n",
    "                edge_index, edge_attr = data.edge_index.to(device), data.edge_attr.to(device)\n",
    "                output = model(features, edge_index, edge_attr)\n",
    "            elif config.architecture == \"gUnet_coo\":\n",
    "                features =  features.to(device)\n",
    "                edge_index, edge_attr = data.edge_index.to(device), data.edge_attr.to(device)\n",
    "                output = model(features, edge_index)\n",
    "\n",
    "            loss_train = F.cross_entropy(output[idx_train], labels[idx_train])            \n",
    "            y_pred = torch.argmax(output, dim=1)\n",
    "\n",
    "            accuracy = metric.update(y_pred[idx_train], labels[idx_train])\n",
    "            f1 = f1score.update(y_pred[idx_train], labels[idx_train])\n",
    "            average_epoch_loss += loss_train.item()\n",
    "            \n",
    "            loss_train.backward()\n",
    "            \n",
    "            clip_grad_norm_(model.parameters(), config.clip)\n",
    "            optimizer.step()\n",
    "        \n",
    "        avg_loss = average_epoch_loss/len(loader)\n",
    "        # Report metrics \n",
    "        train_log(avg_loss, epoch, accuracy, f1, t)\n",
    "        \n",
    "        \n",
    "        \n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_log(avg_loss, epoch, accuracy, f1, t):\n",
    "    # Where the magic happens\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": avg_loss, \"accuracy\":accuracy.compute(), \"F1\": f1.compute() })\n",
    "    print(\n",
    "            \"Epoch: {:04d}\".format(epoch + 1),\n",
    "            \"loss_train: {:.4f}\".format(avg_loss),\n",
    "            \"acc_train: {:.4f}\".format(accuracy.compute()),\n",
    "            \"f1_train: {:.4f}\".format(f1.compute()),\n",
    "            \"time: {:.4f}s\".format(time.time() - t),\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "def _create_adj_mat(data_graph):\n",
    "    edges_index = data_graph.edge_index\n",
    "    row_indices = edges_index[0]\n",
    "    col_indices = edges_index[1]\n",
    "    values = torch.ones(len(edges_index[0]))  # valori tutti a uno\n",
    "    size = torch.Size([len(data_graph.x), len(data_graph.x)])\n",
    "    sparse_matrix = torch.sparse_coo_tensor(\n",
    "        torch.stack([row_indices, col_indices]), values, size=size, device=\"cuda\"\n",
    "    )\n",
    "    adj_matrix = sparse_matrix.to_dense()\n",
    "    return adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters):\n",
    "\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"pytorch-gnn\", config=hyperparameters):\n",
    "      # access all HPs through wandb.config, so logging matches execution!\n",
    "      config = wandb.config\n",
    "\n",
    "      # make the model, data, and optimization problem\n",
    "      model, train_loader, test_loader, criterion, optimizer = make(config)\n",
    "      print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "      train(model, train_loader, criterion, optimizer, config)\n",
    "\n",
    "      # and test its final performance\n",
    "      # test(model, test_loader)\n",
    "      \n",
    "    # Save the model checkpoint\n",
    "\n",
    "      # torch.onnx.export(model, \"model.onnx\")\n",
    "      #wandb.save(\"model.onnx\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hl-turing/VSCodeProjects/Flavio/CARLA/wandb/run-20240807_165918-uapx8nzd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leonardvincentramil-sapienza-universit-di-roma/pytorch-gnn/runs/uapx8nzd' target=\"_blank\">decent-grass-6</a></strong> to <a href='https://wandb.ai/leonardvincentramil-sapienza-universit-di-roma/pytorch-gnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/leonardvincentramil-sapienza-universit-di-roma/pytorch-gnn' target=\"_blank\">https://wandb.ai/leonardvincentramil-sapienza-universit-di-roma/pytorch-gnn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/leonardvincentramil-sapienza-universit-di-roma/pytorch-gnn/runs/uapx8nzd' target=\"_blank\">https://wandb.ai/leonardvincentramil-sapienza-universit-di-roma/pytorch-gnn/runs/uapx8nzd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hl-turing/VSCodeProjects/Flavio/CARLA/carla/data/catalog/graph_catalog.py:294: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(self._data_table)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIN(\n",
      "  (layers_conv): ModuleList(\n",
      "    (0): DenseGINConv(nn=Sequential(\n",
      "      (0): Linear(in_features=31, out_features=50, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    ))\n",
      "    (1-6): 6 x DenseGINConv(nn=Sequential(\n",
      "      (0): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    ))\n",
      "    (7): DenseGCNConv(50, 31)\n",
      "    (8-9): 2 x DenseGCNConv(31, 31)\n",
      "    (10): Linear(in_features=31, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/tmp/ipykernel_233384/2451238061.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.tensor(data.x).squeeze().to(device)\n",
      "/tmp/ipykernel_233384/2451238061.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(data.y).squeeze().long().to(device)\n",
      "  0%|          | 1/1000 [00:00<08:43,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 0.7082 acc_train: 0.5792 f1_train: 0.3838 time: 0.5240s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:01<08:45,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0002 loss_train: 0.3771 acc_train: 0.6476 f1_train: 0.3516 time: 0.5277s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [00:01<08:46,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0003 loss_train: 0.3833 acc_train: 0.6740 f1_train: 0.3363 time: 0.5292s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:02<08:35,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0004 loss_train: 0.4181 acc_train: 0.6927 f1_train: 0.3178 time: 0.5001s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:02<08:29,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0005 loss_train: 0.3713 acc_train: 0.7036 f1_train: 0.2972 time: 0.5015s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [00:03<08:18,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0006 loss_train: 0.3516 acc_train: 0.7115 f1_train: 0.2910 time: 0.4812s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1000 [00:03<08:13,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0007 loss_train: 0.3382 acc_train: 0.7196 f1_train: 0.2887 time: 0.4868s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1000 [00:04<08:08,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0008 loss_train: 0.3077 acc_train: 0.7270 f1_train: 0.2869 time: 0.4819s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1000 [00:04<08:06,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0009 loss_train: 0.3486 acc_train: 0.7317 f1_train: 0.2783 time: 0.4865s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1000 [00:05<08:08,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0010 loss_train: 0.3262 acc_train: 0.7363 f1_train: 0.2700 time: 0.4991s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1000 [00:05<08:05,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0011 loss_train: 0.3625 acc_train: 0.7400 f1_train: 0.2614 time: 0.4858s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1000 [00:06<08:07,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0012 loss_train: 0.3166 acc_train: 0.7435 f1_train: 0.2555 time: 0.4978s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 13/1000 [00:06<08:03,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0013 loss_train: 0.3496 acc_train: 0.7463 f1_train: 0.2507 time: 0.4820s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 14/1000 [00:06<08:03,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0014 loss_train: 0.3368 acc_train: 0.7487 f1_train: 0.2467 time: 0.4899s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 15/1000 [00:07<08:06,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0015 loss_train: 0.4972 acc_train: 0.7512 f1_train: 0.2459 time: 0.5022s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 16/1000 [00:07<08:04,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0016 loss_train: 0.3095 acc_train: 0.7534 f1_train: 0.2439 time: 0.4887s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 17/1000 [00:08<08:02,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0017 loss_train: 0.3166 acc_train: 0.7554 f1_train: 0.2410 time: 0.4877s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 18/1000 [00:08<08:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0018 loss_train: 0.3297 acc_train: 0.7571 f1_train: 0.2384 time: 0.4851s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 19/1000 [00:09<08:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0019 loss_train: 0.3189 acc_train: 0.7587 f1_train: 0.2370 time: 0.4887s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 20/1000 [00:09<07:59,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0020 loss_train: 0.3194 acc_train: 0.7602 f1_train: 0.2351 time: 0.4888s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 21/1000 [00:10<07:58,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0021 loss_train: 0.3188 acc_train: 0.7616 f1_train: 0.2338 time: 0.4855s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 22/1000 [00:10<07:54,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0022 loss_train: 0.3128 acc_train: 0.7630 f1_train: 0.2327 time: 0.4785s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 23/1000 [00:11<07:51,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0023 loss_train: 0.3019 acc_train: 0.7647 f1_train: 0.2328 time: 0.4762s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 24/1000 [00:11<07:45,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0024 loss_train: 0.2942 acc_train: 0.7659 f1_train: 0.2345 time: 0.4616s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 25/1000 [00:12<07:44,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0025 loss_train: 0.3142 acc_train: 0.7661 f1_train: 0.2358 time: 0.4753s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 26/1000 [00:12<07:48,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0026 loss_train: 0.3130 acc_train: 0.7671 f1_train: 0.2332 time: 0.4907s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 27/1000 [00:13<07:59,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0027 loss_train: 0.2742 acc_train: 0.7681 f1_train: 0.2341 time: 0.5209s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 28/1000 [00:13<07:52,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0028 loss_train: 0.2887 acc_train: 0.7692 f1_train: 0.2357 time: 0.4671s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 29/1000 [00:14<07:46,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0029 loss_train: 0.2884 acc_train: 0.7699 f1_train: 0.2391 time: 0.4674s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 30/1000 [00:14<07:49,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0030 loss_train: 0.2989 acc_train: 0.7701 f1_train: 0.2419 time: 0.4936s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 31/1000 [00:15<07:47,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0031 loss_train: 0.3334 acc_train: 0.7702 f1_train: 0.2383 time: 0.4757s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 32/1000 [00:15<07:45,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0032 loss_train: 0.2775 acc_train: 0.7705 f1_train: 0.2370 time: 0.4784s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 33/1000 [00:16<07:45,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0033 loss_train: 0.2668 acc_train: 0.7714 f1_train: 0.2366 time: 0.4803s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 34/1000 [00:16<07:48,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0034 loss_train: 0.2857 acc_train: 0.7723 f1_train: 0.2357 time: 0.4947s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 35/1000 [00:17<07:51,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0035 loss_train: 0.3033 acc_train: 0.7726 f1_train: 0.2349 time: 0.4970s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 36/1000 [00:17<07:51,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0036 loss_train: 0.2753 acc_train: 0.7731 f1_train: 0.2343 time: 0.4886s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 37/1000 [00:18<07:48,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0037 loss_train: 0.2713 acc_train: 0.7739 f1_train: 0.2369 time: 0.4791s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 37/1000 [00:18<07:59,  2.01it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_233384/1643529747.py\", line 13, in model_pipeline\n",
      "    train(model, train_loader, criterion, optimizer, config)\n",
      "  File \"/tmp/ipykernel_233384/2451238061.py\", line 19, in train\n",
      "    norm_adj = normalize_adj(adj).to(device)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hl-turing/VSCodeProjects/Flavio/CARLA/carla/models/catalog/parse_gnn.py\", line 143, in normalize_adj\n",
      "    D_tilde = torch.pow(get_degree_matrix(A_tilde), -0.5)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hl-turing/VSCodeProjects/Flavio/CARLA/carla/models/catalog/parse_gnn.py\", line 133, in get_degree_matrix\n",
      "    return torch.diag(sum(adj))\n",
      "                      ^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>F1</td><td></td></tr><tr><td>accuracy</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>F1</td><td>0.23694</td></tr><tr><td>accuracy</td><td>0.77389</td></tr><tr><td>epoch</td><td>36</td></tr><tr><td>loss</td><td>0.27131</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">decent-grass-6</strong> at: <a href='https://wandb.ai/leonardvincentramil-sapienza-universit-di-roma/pytorch-gnn/runs/uapx8nzd' target=\"_blank\">https://wandb.ai/leonardvincentramil-sapienza-universit-di-roma/pytorch-gnn/runs/uapx8nzd</a><br/> View project at: <a href='https://wandb.ai/leonardvincentramil-sapienza-universit-di-roma/pytorch-gnn' target=\"_blank\">https://wandb.ai/leonardvincentramil-sapienza-universit-di-roma/pytorch-gnn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240807_165918-uapx8nzd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m model_pipeline(config)\n",
      "Cell \u001b[0;32mIn[30], line 13\u001b[0m, in \u001b[0;36mmodel_pipeline\u001b[0;34m(hyperparameters)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(model)\n\u001b[1;32m     12\u001b[0m \u001b[39m# and use them to train the model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m train(model, train_loader, criterion, optimizer, config)\n\u001b[1;32m     15\u001b[0m \u001b[39m# and test its final performance\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m# test(model, test_loader)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m torch\u001b[39m.\u001b[39monnx\u001b[39m.\u001b[39mexport(model, \u001b[39m\"\u001b[39m\u001b[39mmodel.onnx\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[32], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loader, criterion, optimizer, config)\u001b[0m\n\u001b[1;32m     16\u001b[0m data\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m adj \u001b[39m=\u001b[39m _create_adj_mat(data)\n\u001b[0;32m---> 19\u001b[0m norm_adj \u001b[39m=\u001b[39m normalize_adj(adj)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(data\u001b[39m.\u001b[39mx)\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     21\u001b[0m labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(data\u001b[39m.\u001b[39my)\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/VSCodeProjects/Flavio/CARLA/carla/models/catalog/parse_gnn.py:143\u001b[0m, in \u001b[0;36mnormalize_adj\u001b[0;34m(adj)\u001b[0m\n\u001b[1;32m    140\u001b[0m A_tilde \u001b[39m=\u001b[39m adj \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39meye(adj\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), device\u001b[39m=\u001b[39madj\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    142\u001b[0m \u001b[39m# Compute the degree matrix and its inverse square root\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m D_tilde \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mpow(get_degree_matrix(A_tilde), \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[1;32m    144\u001b[0m D_tilde[torch\u001b[39m.\u001b[39misinf(D_tilde)] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# Set inf values to 0\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[39m# Compute the normalized adjacency matrix\u001b[39;00m\n",
      "File \u001b[0;32m~/VSCodeProjects/Flavio/CARLA/carla/models/catalog/parse_gnn.py:133\u001b[0m, in \u001b[0;36mget_degree_matrix\u001b[0;34m(adj)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_degree_matrix\u001b[39m(adj):\n\u001b[0;32m--> 133\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mdiag(\u001b[39msum\u001b[39m(adj))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model_pipeline(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([[31]*i for i in range(3)] + [[50]*i for i in range(3)] + [[100]*i for i in range(3)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameterTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    \n",
    "    'metric':{\n",
    "        'goal': 'minimize',\n",
    "        'name': 'loss'\n",
    "    },\n",
    "    \n",
    "    'parameters':{\n",
    "        'hidden_list_conv': {\n",
    "            'values': [[31]*i for i in range(7)] + [[50]*i for i in range(7)] + [[100]*i for i in range(7)]\n",
    "        },\n",
    "        \n",
    "        'hidden_list_att':{\n",
    "            'values': [[31]*i for i in range(7)] + [[50]*i for i in range(7)] + [[100]*i for i in range(7)]\n",
    "        },\n",
    "        \n",
    "        'alpha':{\n",
    "            'max': 0.4,\n",
    "            'min': 0.1,\n",
    "            'distribution': 'uniform'\n",
    "        },\n",
    "        \n",
    "        'nheads':{\n",
    "            'max': 8,\n",
    "            'min': 1,\n",
    "            'distribution': 'int_uniform'   \n",
    "        },\n",
    "        \n",
    "        'dropout':{\n",
    "            'values': [0.0]\n",
    "        },\n",
    "        \n",
    "        \n",
    "        'epochs':{\n",
    "            'max': 2000,\n",
    "            'min': 500,\n",
    "            'distribution': 'int_uniform'   \n",
    "        },\n",
    "        \n",
    "        'classes':{\n",
    "            'values': [2]\n",
    "        },\n",
    "        \n",
    "        'batch_size':{\n",
    "            'max': 2048,\n",
    "            'min': 512,\n",
    "            'distribution': 'int_uniform'   \n",
    "        },\n",
    "        \n",
    "        'num_neig':{\n",
    "            'values': [[31]*i for i in range(4)] + [[50]*i for i in range(4)] + [[100]*i for i in range(4)]\n",
    "        },\n",
    "        \n",
    "        'learning_rate':{\n",
    "            'values': [0.01, 0.02, 0.001, 0.002, 0.0001, 0.0002]\n",
    "        },\n",
    "\n",
    "        'clip':{\n",
    "            'max': 4.0,\n",
    "            'min': 1.0,\n",
    "            'distribution': 'int_uniform'   \n",
    "        },\n",
    "        \n",
    "        'dataset':{\n",
    "            'values': ['AML']\n",
    "        },\n",
    "\n",
    "        'architecture':{\n",
    "            'values': ['gnn'],\n",
    "            'distribution': 'categorical'\n",
    "        }\n",
    "        \n",
    "    }\n",
    "    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'bayes',\n",
      " 'metric': {'goal': 'minimize', 'name': 'loss'},\n",
      " 'parameters': {'alpha': {'distribution': 'uniform', 'max': 0.4, 'min': 0.1},\n",
      "                'architecture': {'distribution': 'categorical',\n",
      "                                 'values': ['gnn']},\n",
      "                'batch_size': {'distribution': 'int_uniform',\n",
      "                               'max': 2048,\n",
      "                               'min': 512},\n",
      "                'classes': {'values': [2]},\n",
      "                'clip': {'distribution': 'int_uniform', 'max': 4.0, 'min': 1.0},\n",
      "                'dataset': {'values': ['AML']},\n",
      "                'dropout': {'values': [0.0]},\n",
      "                'epochs': {'distribution': 'int_uniform',\n",
      "                           'max': 2000,\n",
      "                           'min': 500},\n",
      "                'hidden_list_att': {'values': [[],\n",
      "                                               [31],\n",
      "                                               [31, 31],\n",
      "                                               [31, 31, 31],\n",
      "                                               [31, 31, 31, 31],\n",
      "                                               [31, 31, 31, 31, 31],\n",
      "                                               [31, 31, 31, 31, 31, 31],\n",
      "                                               [],\n",
      "                                               [50],\n",
      "                                               [50, 50],\n",
      "                                               [50, 50, 50],\n",
      "                                               [50, 50, 50, 50],\n",
      "                                               [50, 50, 50, 50, 50],\n",
      "                                               [50, 50, 50, 50, 50, 50],\n",
      "                                               [],\n",
      "                                               [100],\n",
      "                                               [100, 100],\n",
      "                                               [100, 100, 100],\n",
      "                                               [100, 100, 100, 100],\n",
      "                                               [100, 100, 100, 100, 100],\n",
      "                                               [100, 100, 100, 100, 100, 100]]},\n",
      "                'hidden_list_conv': {'values': [[],\n",
      "                                                [31],\n",
      "                                                [31, 31],\n",
      "                                                [31, 31, 31],\n",
      "                                                [31, 31, 31, 31],\n",
      "                                                [31, 31, 31, 31, 31],\n",
      "                                                [31, 31, 31, 31, 31, 31],\n",
      "                                                [],\n",
      "                                                [50],\n",
      "                                                [50, 50],\n",
      "                                                [50, 50, 50],\n",
      "                                                [50, 50, 50, 50],\n",
      "                                                [50, 50, 50, 50, 50],\n",
      "                                                [50, 50, 50, 50, 50, 50],\n",
      "                                                [],\n",
      "                                                [100],\n",
      "                                                [100, 100],\n",
      "                                                [100, 100, 100],\n",
      "                                                [100, 100, 100, 100],\n",
      "                                                [100, 100, 100, 100, 100],\n",
      "                                                [100,\n",
      "                                                 100,\n",
      "                                                 100,\n",
      "                                                 100,\n",
      "                                                 100,\n",
      "                                                 100]]},\n",
      "                'learning_rate': {'values': [0.01,\n",
      "                                             0.02,\n",
      "                                             0.001,\n",
      "                                             0.002,\n",
      "                                             0.0001,\n",
      "                                             0.0002]},\n",
      "                'nheads': {'distribution': 'int_uniform', 'max': 8, 'min': 1},\n",
      "                'num_neig': {'values': [[],\n",
      "                                        [31],\n",
      "                                        [31, 31],\n",
      "                                        [31, 31, 31],\n",
      "                                        [],\n",
      "                                        [50],\n",
      "                                        [50, 50],\n",
      "                                        [50, 50, 50],\n",
      "                                        [],\n",
      "                                        [100],\n",
      "                                        [100, 100],\n",
      "                                        [100, 100, 100]]}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: xuzk9tp7\n",
      "Sweep URL: https://wandb.ai/leonardvincentramil-sapienza-universit-di-roma/pytorch-gnn/sweeps/xuzk9tp7\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"pytorch-gnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sweep(hyperparameters=None):\n",
    "\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(config=hyperparameters):\n",
    "      # access all HPs through wandb.config, so logging matches execution!\n",
    "      config = wandb.config\n",
    "\n",
    "      # make the model, data, and optimization problem\n",
    "      model, train_loader, test_loader, criterion, optimizer = make(config)\n",
    "      print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "      train(model, train_loader, criterion, optimizer, config)\n",
    "\n",
    "      # and test its final performance\n",
    "      # test(model, test_loader)\n",
    "      \n",
    "    # Save the model checkpoint\n",
    "\n",
    "      # torch.onnx.export(model, \"model.onnx\")\n",
    "      #wandb.save(\"model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1neomm17 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha: 0.36983818162277937\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarchitecture: gnn\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclasses: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: AML\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1775\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_list_att: [50, 50, 50, 50, 50]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_list_conv: [50]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnheads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neig: [100]\n",
      "2024-08-07 22:56:29.224233: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-07 22:56:29.249942: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-07 22:56:29.724851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n",
      "[WARNING] From /home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term [deprecation.py _log_deprecation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/hl-turing/VSCodeProjects/Flavio/CARLA/wandb.py\", line 1, in <module>\n",
      "    import wandb\n",
      "  File \"/home/hl-turing/VSCodeProjects/Flavio/CARLA/wandb.py\", line 38, in <module>\n",
      "    wandb.login()\n",
      "    ^^^^^^^^^^^\n",
      "AttributeError: partially initialized module 'wandb' has no attribute 'login' (most likely due to a circular import)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 1neomm17 errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_250384/1996428651.py\", line 4, in train_sweep\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     with wandb.init(config=hyperparameters):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_init.py\", line 1195, in init\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wandb._sentry.reraise(e)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/analytics/sentry.py\", line 155, in reraise\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise exc.with_traceback(sys.exc_info()[2])\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_init.py\", line 1180, in init\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wi.setup(kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._wl = wandb_setup.setup(settings=setup_settings)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py\", line 325, in setup\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     ret = _setup(settings=settings)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py\", line 318, in _setup\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     wl = _WandbSetup(settings=settings)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py\", line 114, in __init__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._setup()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py\", line 250, in _setup\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._setup_manager()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py\", line 283, in _setup_manager\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._manager = wandb_manager._Manager(settings=self._settings)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/wandb_manager.py\", line 145, in __init__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._service.start()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/service/service.py\", line 253, in start\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._launch_server()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/service/service.py\", line 247, in _launch_server\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     _sentry.reraise(e)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/analytics/sentry.py\", line 155, in reraise\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise exc.with_traceback(sys.exc_info()[2])\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/service/service.py\", line 245, in _launch_server\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._wait_for_ports(fname, proc=internal_proc)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/hl-turing/anaconda3/envs/cfgnn/lib/python3.11/site-packages/wandb/sdk/service/service.py\", line 109, in _wait_for_ports\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise ServiceStartProcessError(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb.sdk.service.service.ServiceStartProcessError: The wandb service process exited with 1. Ensure that `sys.executable` is a valid python interpreter. You can override it with the `_executable` setting or with the `WANDB__EXECUTABLE` environment variable.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m {'command': ['/home/hl-turing/anaconda3/envs/cfgnn/bin/python', '-m', 'wandb', 'service', '--debug', '--port-filename', '/tmp/tmp4rrn2ym7/port-250384.txt', '--pid', '250384', '--serve-sock'], 'sys_executable': '/home/hl-turing/anaconda3/envs/cfgnn/bin/python', 'which_python': '/home/hl-turing/anaconda3/envs/cfgnn/bin/python3', 'proc_out': '', 'proc_err': ''}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train_sweep, count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
